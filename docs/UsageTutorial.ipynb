{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b3c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install quantum-image-classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9fd4b1",
   "metadata": {},
   "source": [
    "# Quantum image classifier\n",
    "## Package usage\n",
    "\n",
    "If you want to use this package you can install it using `pip install quantum-image-classifier`, just as we did on the top of this notebook. After that, you can easily import it as any other package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e058265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantum_image_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33dc822",
   "metadata": {},
   "source": [
    "## Features\n",
    "Here we will explain the several options that this package offers, in order to generate a template which you could use to try it yourself.\n",
    "\n",
    "### Data treatment\n",
    "You can obtain the data you want to test the algorithms in this section of the package. First of all, you can generate synthetic data by using the function `generate_synthetic_data` like we show you here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6dbee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_image_classifier import data_generator as dg\n",
    "\n",
    "n_dim = 8\n",
    "n_clusters = 4\n",
    "n_samples = 250\n",
    "\n",
    "train_X, train_y, test_X, test_y = dg.generate_synthetic_data(n_dim, n_clusters, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c407a4c",
   "metadata": {},
   "source": [
    "Other option is to use a dataset of your own. To do this you need to be aware of a very important aspect of the nature of the quantum algorithms: **you can operate with a very limited number of qubits**. This means that, if you wish to classify an actual image, you need to preprocess it before applying the algorithms in order to reduce its dimensionality and be able to use the data (we recommend this to data with a dimension greater than 32). To do this you can use one of the three options we give you:\n",
    "\n",
    "1. **Use PCA.** You can use PCA method to achieve a dimension reduction. The only problem this method has is that you have to assume a linear relationship between the input and the output, so, if there is a non-linear relationship, you can generate non-accurate data.\n",
    "2. **Use simple autoencoder (AE).** You can use a simple autoencoder in order to achieve a dimension reduction. This solves the non-linear cases, but increases the execution time, because you have to train a neural network.\n",
    "3. **Use autoencoder based on CNN.** With this less simple implementation of the autoencoder you will achieve much more accuracy than with the simple autoencoder by trading time of execution and complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b03e437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a67b7",
   "metadata": {},
   "source": [
    "### Algorithms\n",
    "#### Nearest centroid algorithm\n",
    "In order to use this algorithm, first we need to instance the class NearestCentroid. We can instance this class in two ways: either by giving the training set as an argument (along with the dimension and the labels associated to this dataset) or empty. In the first way, we will need to send the dataset with the associated labels to the function `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e6417d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 3 2 2 2 2 1 1 3 2 3 2 1 1 2 1 2 2 3 0 1 1 3 0 1 0 2 1 2 3 0 3 1 1 2 1\n",
      " 1 0 3 2 1 0 3 0 3 0 3 0 3 0 0 1 2 0 1 2 2 0 1 2 2 0]\n",
      "[3 1 3 2 2 2 2 1 1 3 2 3 2 1 1 2 1 2 2 3 0 1 1 3 0 1 0 2 1 2 3 0 3 1 1 2 1\n",
      " 1 0 3 2 1 0 3 0 3 0 3 0 3 0 0 1 2 0 1 2 2 0 1 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "from quantum_image_classifier import NearestCentroid\n",
    "\n",
    "# Empty instance\n",
    "nearest_centroid = NearestCentroid()\n",
    "nearest_centroid.fit(train_X, train_y, n_dim)\n",
    "labels_predicted = nearest_centroid.predict(test_X)\n",
    "\n",
    "print(test_y)\n",
    "print(labels_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af1c4c4",
   "metadata": {},
   "source": [
    "On the contrary, if we have already given the dataset with its associated labels on the construction, we just need to call fit wthout arguments. By the way, if you call here `fit` with arguments, then you will override the data of the construction, naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f698ecea",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NearestCentroid' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Instance with dataset and labels.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m nearest_centroid \u001b[38;5;241m=\u001b[39m NearestCentroid(train_X, train_y, n_dim)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mnearest_centroid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m()\n\u001b[0;32m      4\u001b[0m labels_predicted \u001b[38;5;241m=\u001b[39m nearest_centroid\u001b[38;5;241m.\u001b[39mpredict(test_X)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_y)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NearestCentroid' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "# Instance with dataset and labels.\n",
    "nearest_centroid = NearestCentroid(train_X, train_y, n_dim)\n",
    "nearest_centroid.fit()\n",
    "labels_predicted = nearest_centroid.predict(test_X)\n",
    "\n",
    "print(test_y)\n",
    "print(labels_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
