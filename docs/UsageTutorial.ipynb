{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# NOT NEEDED IF YOU ARE IN BINDER\n",
    "import sys\n",
    "!{sys.executable} -m pip install quantum-image-classifier==1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9fd4b1",
   "metadata": {},
   "source": [
    "# Quantum image classifier\n",
    "## Package usage\n",
    "\n",
    "If you want to use this package you can install it using `pip install quantum-image-classifier`, just as we did on the top of this notebook. After that, you can easily import it as any other package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e058265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantum_image_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33dc822",
   "metadata": {},
   "source": [
    "## Features\n",
    "In this package you can do three things: treat data to feed into the algorithm, call a quantum algorithm to classify the data and visualize the accuracy or the points of the dataset. We see how in the next sections.\n",
    "\n",
    "### Data treatment\n",
    "You can obtain the data you want to test the algorithms in this section of the package. First of all, you can generate synthetic data by using the function `generate_synthetic_data` like we show you here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68beed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_image_classifier import data_generator as dg\n",
    "\n",
    "n_dim = 8\n",
    "n_clusters = 2\n",
    "n_samples = 1000\n",
    "\n",
    "train_X_syn, train_y_syn, test_X_syn, test_y_syn = dg.generate_synthetic_data(n_dim, n_clusters, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c407a4c",
   "metadata": {},
   "source": [
    "Other option is to use the MNIST dataset. To do this you need to be aware of a very important aspect of the nature of the quantum algorithms: **you can operate with a very limited number of qubits**. This means that, if you wish to classify an actual image, you need to preprocess it before applying the algorithms in order to reduce its dimensionality and be able to use the data (we recommend this to data with a dimension greater than 32). To do this to the MNIST dataset you can use one of the three options we give you:\n",
    "\n",
    "1. **Use PCA (PCA).** You can use PCA method to achieve a dimension reduction. The only problem this method has is that you have to assume a linear relationship between the input and the output, so, if there is a non-linear relationship, you can generate non-accurate data.\n",
    "2. **Use simple autoencoder (AE).** You can use a simple autoencoder in order to achieve a dimension reduction. This solves the non-linear cases, but increases the execution time, because you have to train a neural network.\n",
    "3. **Use autoencoder based on CNN (AE_CNN).** With this less simple implementation of the autoencoder you will achieve much more accuracy than with the simple autoencoder by trading time of execution and complexity.\n",
    "\n",
    "You have an example of how can you apply this preprocess to the data below, using the function `get_MNIST`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03e437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_image_classifier import data_loader as dl\n",
    "\n",
    "# It will take time to compute this operations.\n",
    "\n",
    "train_X_pca, train_y_pca, test_X_pca, test_y_pca = dl.get_MNIST(8, \"PCA\")\n",
    "print(\"PCA PREPROCESS\")\n",
    "print(train_X_pca[:10])\n",
    "\n",
    "train_X_ae, train_y_ae, test_X_ae, test_y_ae = dl.get_MNIST(8, \"AE\")\n",
    "print(\"SIMPLE AUTOENCODER PREPROCESS\")\n",
    "print(train_X_ae[:10])\n",
    "\n",
    "train_X_ae_cnn, train_y_ae_cnn, test_X_ae_cnn, test_y_ae_cnn = dl.get_MNIST(8, \"AE_CNN\")\n",
    "print(\"CNN AUTOENCODER PREPROCESS\")\n",
    "print(train_X_ae_cnn[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a67b7",
   "metadata": {},
   "source": [
    "### Algorithms\n",
    "#### Nearest centroid algorithm\n",
    "In order to use this algorithm, first we need to instance the class NearestCentroid. We can instance this class in two ways: either by giving the training set as an argument (along with the dimension of the data points and the labels associated to this dataset) or empty. In the first way, we will need to send the dataset with the associated labels to the function `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_image_classifier import NearestCentroid\n",
    "\n",
    "# Empty instance\n",
    "nearest_centroid = NearestCentroid()\n",
    "nearest_centroid.fit(train_X_syn, train_y_syn, n_dim)\n",
    "labels_predicted = nearest_centroid.predict(test_X_syn)\n",
    "\n",
    "print(test_y_syn[:20])\n",
    "print(labels_predicted[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af1c4c4",
   "metadata": {},
   "source": [
    "On the contrary, if we have already given the dataset with its associated labels on the construction, we just need to call fit wthout arguments. By the way, if you call here `fit` with arguments, then you will override the data of the construction, naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f698ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance with dataset and labels\n",
    "nearest_centroid = NearestCentroid(train_X_syn, train_y_syn, n_dim)\n",
    "nearest_centroid.fit()\n",
    "labels_predicted = nearest_centroid.predict(test_X_syn)\n",
    "\n",
    "print(test_y_syn[:20])\n",
    "print(labels_predicted[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8224b1e9",
   "metadata": {},
   "source": [
    "### Visual representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f4e86f",
   "metadata": {},
   "source": [
    "In this package we also implement a module to visualize the accuracy of the methods, we just need to execute the nearest centroid algorithm as we did above and calculate the percetages of accuracy like we show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff130b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid as classicalNC\n",
    "from quantum_image_classifier import NearestCentroid as quantumNC\n",
    "\n",
    "from quantum_image_classifier import error_graph\n",
    "\n",
    "def _calc_accuracy(labels, predictions):\n",
    "    counts = 0\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        if prediction == label:\n",
    "            counts += 1\n",
    "    return counts / len(labels)\n",
    "\n",
    "quantum = quantumNC()\n",
    "quantum.fit(train_X_syn, train_y_syn, n_dim)\n",
    "labelsQ = quantum.predict(test_X_syn)\n",
    "\n",
    "classical = classicalNC()\n",
    "classical.fit(train_X_syn, train_y_syn)\n",
    "labelsC = classical.predict(test_X_syn)\n",
    "\n",
    "accuracyQ = _calc_accuracy(test_y_syn, labelsQ)\n",
    "accuracyC = _calc_accuracy(test_y_syn, labelsC)\n",
    "\n",
    "error_graph(\"./clasico_vs_cuantico_gen.png\",\n",
    "                 (\"NC clasico\", accuracyC), (\"NC cuantico\", accuracyQ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227cfb05",
   "metadata": {},
   "source": [
    "To complement this, due to the stochastic nature of the quantum algorithms, we have also created a function which shows the same as before, buf of several simulations, representing the average and the standard deviation of the result in order to get a real impression on which is the actual performance of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_image_classifier import variance_error_graph\n",
    "from tqdm import tqdm\n",
    "\n",
    "accuracyQ = []\n",
    "accuracyC = []\n",
    "\n",
    "for _ in tqdm(range(20)):\n",
    "    quantum = quantumNC()\n",
    "    quantum.fit(train_X_syn, train_y_syn, n_dim)\n",
    "    labelsQ = quantum.predict(test_X_syn)\n",
    "\n",
    "    classical = classicalNC()\n",
    "    classical.fit(train_X_syn, train_y_syn)\n",
    "    labelsC = classical.predict(test_X_syn)\n",
    "\n",
    "    accuracyQ.append(_calc_accuracy(test_y_syn, labelsQ))\n",
    "    accuracyC.append(_calc_accuracy(test_y_syn, labelsC))\n",
    "    \n",
    "# The plot will be saved in the directory of the notebook with this name\n",
    "variance_error_graph(\"./clasico_vs_cuantico_gen.png\",\n",
    "                     (\"NC clasico\", accuracyC), (\"NC cuantico\", accuracyQ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc13699",
   "metadata": {},
   "source": [
    "On the other hand, we also have implemented a function to visualize a cloud point plot in case the dimension of the data points is equal to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a6ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_image_classifier import cloud_point\n",
    "\n",
    "n_clusters = 2\n",
    "cloud_point(train_X_syn, train_y_syn, \"./cloud_point_gen.png\", n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e2c7e",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31111779",
   "metadata": {},
   "source": [
    "This package is a result of a End of Degree project in which we tested the algorithm in different ways. First, we showed how well we were estimating the distance using the synthetic data and the real data. Second, we tested the quantum nearest centroid against its classical version by measuring its accuracy through a certain number of iterations and using, again, both the real data from MNIST and the synthetic data. Third, and last, we also showed how the reduction methods and the number of clusters affected the classffication task, once again, taking both types of data into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a560376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_image_classifier import data_generator, data_loader\n",
    "import numpy as np\n",
    "\n",
    "# TEST OF QUANTUM DISTANCE WITH CLOUD POINT PLOT\n",
    "def distanceComparison():\n",
    "    n_dim = 2\n",
    "    n_clusters = 4\n",
    "    train_X, train_y, test_X, test_y = data_generator.generate_synthetic_data(\n",
    "        n_dim, n_clusters, 1000)\n",
    "    cloud_point(train_X, train_y, \"./cloud_point_gen.png\", n_clusters)\n",
    "\n",
    "    quantum = quantumNC()\n",
    "    quantum.fit(train_X, train_y, n_dim)\n",
    "    labels, differenceGen, distanceGen = quantum.predict(test_X, test_distance=True)\n",
    "\n",
    "    train_X, train_y, test_X, test_y = data_loader.get_MNIST(n_dim, \"PCA\", [0,1])\n",
    "    cloud_point(train_X, train_y, \"./could_point_MNIST.png\", n_clusters)\n",
    "\n",
    "    quantum = quantumNC()\n",
    "    quantum.fit(train_X, train_y, n_dim)\n",
    "    labels, differenceMNIST, distanceMNIST = quantum.predict(test_X, test_distance=True)\n",
    "\n",
    "    print(\"Generado: MEDIA {} DIFERENCIA {}\".format(np.mean(distanceGen), np.mean(np.absolute(differenceGen))))\n",
    "    print(\"MNIST: MEDIA {} DIFERENCIA {}\".format(np.mean(distanceMNIST), np.mean(np.absolute(differenceMNIST))))\n",
    "\n",
    "distanceComparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a67dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARISON BETWEEN CLASSIC AND QUANTUM PERFORMANCE WITH SYNTHETIC DATA\n",
    "def quantumVSclasico_gen(iterations):\n",
    "    n_dim = 8\n",
    "    n_clusters = 2\n",
    "    accuracyQ = []\n",
    "    accuracyC = []\n",
    "\n",
    "    for _ in tqdm(range(iterations)):\n",
    "        train_X, train_y, test_X, test_y = data_generator.generate_synthetic_data(\n",
    "            n_dim, n_clusters, 1000)\n",
    "\n",
    "        quantum = quantumNC()\n",
    "        quantum.fit(train_X, train_y, n_dim)\n",
    "        labelsQ = quantum.predict(test_X)\n",
    "\n",
    "        classical = classicalNC()\n",
    "        classical.fit(train_X, train_y)\n",
    "        labelsC = classical.predict(test_X)\n",
    "\n",
    "        accuracyQ.append(_calc_accuracy(test_y, labelsQ))\n",
    "        accuracyC.append(_calc_accuracy(test_y, labelsC))\n",
    "\n",
    "    variance_error_graph(\"./clasico_vs_cuantico_gen.png\",\n",
    "                         (\"NC clasico\", accuracyC), (\"NC cuantico\", accuracyQ))\n",
    "quantumVSclasico_gen(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f16a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARISON BETWEEN CLASSIC AND QUANTUM PERFORMANCE WITH MNIST DATA\n",
    "def quantumVSclassic_MNIST(iterations):\n",
    "    n_dim = 8\n",
    "    n_clusters = 2\n",
    "    accuracyQ = []\n",
    "    accuracyC = []\n",
    "\n",
    "    for _ in tqdm(range(iterations)):\n",
    "        train_X, train_y, test_X, test_y = data_loader.get_MNIST(n_dim, \"PCA\", [\n",
    "                                                                 1, 0, 6, 9])\n",
    "\n",
    "        quantum = quantumNC()\n",
    "        quantum.fit(train_X, train_y, n_dim)\n",
    "        labelsQ = quantum.predict(test_X)\n",
    "\n",
    "        classical = classicalNC()\n",
    "        classical.fit(train_X, train_y)\n",
    "        labelsC = classical.predict(test_X)\n",
    "\n",
    "        accuracyQ.append(_calc_accuracy(test_y, labelsQ))\n",
    "        accuracyC.append(_calc_accuracy(test_y, labelsC))\n",
    "\n",
    "    variance_error_graph(\"./clasico_vs_cuantico_MNIST.png\",\n",
    "                         (\"NC clasico\", accuracyC), (\"NC cuantico\", accuracyQ))\n",
    "quantumVSclassic_MNIST(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARISON BETWEEN NUMBER OF CLUSTERS\n",
    "def numClustersAccuracy(iterations):\n",
    "    n_dim = 8\n",
    "    accuracy2 = []\n",
    "    accuracy4 = []\n",
    "    accuracy6 = []\n",
    "\n",
    "    for _ in tqdm(range(iterations)):\n",
    "        train_X, train_y, test_X, test_y = data_loader.get_MNIST(n_dim, \"PCA\", [\n",
    "                                                                 1, 0])\n",
    "        quantum = quantumNC()\n",
    "        quantum.fit(train_X, train_y, n_dim)\n",
    "        accuracy2.append(_calc_accuracy(test_y, quantum.predict(test_X)))\n",
    "\n",
    "        train_X, train_y, test_X, test_y = data_loader.get_MNIST(n_dim, \"PCA\", [\n",
    "                                                                 1, 0, 6, 9])\n",
    "        quantum = quantumNC()\n",
    "        quantum.fit(train_X, train_y, n_dim)\n",
    "        accuracy4.append(_calc_accuracy(test_y, quantum.predict(test_X)))\n",
    "\n",
    "        train_X, train_y, test_X, test_y = data_loader.get_MNIST(\n",
    "            n_dim, \"PCA\", [1, 0, 4, 5, 6, 9])\n",
    "        quantum = quantumNC()\n",
    "        quantum.fit(train_X, train_y, n_dim)\n",
    "        accuracy6.append(_calc_accuracy(test_y, quantum.predict(test_X)))\n",
    "\n",
    "    variance_error_graph(\"./clusters_accuracy.png\",\n",
    "                         (\"2 clusters\", accuracy2), (\"4 clusters\", accuracy4), (\"6 clusters\", accuracy6))\n",
    "    \n",
    "numClustersAccuracy(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accabcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARISON BETWEEN TYPES OF METHODS FOR DIMENSIONALITY REDUCTION\n",
    "def reductionMethodAccuracy(iterations):\n",
    "    n_dim = 8\n",
    "    accuracyPCA = []\n",
    "    accuracyAE = []\n",
    "    accuracyAECNN = []\n",
    "\n",
    "    for _ in tqdm(range(iterations)):\n",
    "        train_X, train_y, test_X, test_y = data_loader.get_MNIST(n_dim, \"PCA\", [\n",
    "                                                                 1, 0, 6, 9])\n",
    "        quantum = quantumNC()\n",
    "        quantum.fit(train_X, train_y, n_dim)\n",
    "        accuracyPCA.append(_calc_accuracy(test_y, quantum.predict(test_X)))\n",
    "\n",
    "        train_X, train_y, test_X, test_y = data_loader.get_MNIST(n_dim, \"AE\", [\n",
    "                                                                 1, 0, 6, 9])\n",
    "        quantum = quantumNC()\n",
    "        quantum.fit(train_X, train_y, n_dim)\n",
    "        accuracyAE.append(_calc_accuracy(test_y, quantum.predict(test_X)))\n",
    "\n",
    "        train_X, train_y, test_X, test_y = data_loader.get_MNIST(n_dim, \"AE_CNN\", [\n",
    "                                                                 1, 0, 6, 9])\n",
    "        quantum = quantumNC()\n",
    "        quantum.fit(train_X, train_y, n_dim)\n",
    "        accuracyAECNN.append(_calc_accuracy(test_y, quantum.predict(test_X)))\n",
    "\n",
    "    variance_error_graph(\"./reduction_accuracy.png\",\n",
    "                         (\"PCA\", accuracyPCA), (\"AE\", accuracyAE), (\"AE CNN\", accuracyAECNN))\n",
    "reductionMethodAccuracy(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66716c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
